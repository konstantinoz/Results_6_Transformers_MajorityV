Model,Accuracy,F1,Precision,Recall,MCC,kappa
"T5,Albert,GPT2",0.9407582938388626,0.9407560170275672,0.941184706185196,0.9407582938388626,0.8889837111715156,0.8888442731094454
"DeBERTa,T5,GPT2",0.9375987361769352,0.93824909284947,0.941854852168465,0.9375987361769352,0.883965647710447,0.8830085520474732
"DeBERTa,Albert,GPT2",0.9360189573459716,0.936689830678026,0.9400886418348212,0.9360189573459716,0.8809681370674431,0.8800787266214561
"DeBERTa,T5,Albert",0.9360189573459716,0.936689830678026,0.9400886418348212,0.9360189573459716,0.8809681370674431,0.8800787266214561
"DeBERTa,T5,Pythia",0.9328593996840442,0.9335265004017516,0.9368225005135524,0.9328593996840442,0.8752314032649599,0.8743519686142637
"T5,Albert,Pythia",0.9320695102685624,0.9321855755885836,0.9325069107708104,0.9320695102685624,0.8730472128451582,0.8729722414082772
"T5,GPT2,Pythia",0.9320695102685624,0.9322118321935202,0.9326623299393676,0.9320695102685624,0.8733543089761407,0.8732285637437605
"DeBERTa,Albert,Pythia",0.9320695102685624,0.932760048553168,0.9359092152105272,0.9320695102685624,0.8736675167376032,0.8728418347980963
"DeBERTa,GPT2,Pythia",0.9304897314375988,0.9311636929126088,0.9343996114267082,0.9304897314375988,0.8710100108107282,0.8701188781595045
"Bart,T5,GPT2",0.9265402843601896,0.9256055387036882,0.9286975768535798,0.9265402843601896,0.8720179153767506,0.8692998085088669
"Bart,T5,Albert",0.9257503949447078,0.9247818472028536,0.9283567077827504,0.9257503949447078,0.8707028545960449,0.8675574519800608
"Albert,GPT2,Pythia",0.924170616113744,0.9247341146983074,0.926250031966739,0.924170616113744,0.8568635468350562,0.8562782480363845
"Bart,Albert,GPT2",0.924170616113744,0.9232164228830652,0.9264538531456052,0.924170616113744,0.8677434601315016,0.8648379035728941
"Bart,T5,Pythia",0.9210110584518169,0.9200715000428774,0.9228889148636314,0.9210110584518169,0.8619029806379654,0.8592742285093072
"Bart,Albert,Pythia",0.9202211690363348,0.9192686939346796,0.9221410266951884,0.9202211690363348,0.8604746710593337,0.8577806548056004
"Bart,GPT2,Pythia",0.919431279620853,0.9185322358864174,0.9208657847657008,0.919431279620853,0.8589522703984146,0.8567029425766438
"Bart,DeBERTa,Albert",0.9186413902053712,0.9177317253067018,0.920114749241404,0.9186413902053712,0.8575188425796945,0.8552103424039227
"Bart,DeBERTa,GPT2",0.9186413902053712,0.917753243570358,0.9199515267477444,0.9186413902053712,0.857499554228036,0.8553505584175286
"Bart,DeBERTa,T5",0.9186413902053712,0.9177317253067018,0.920114749241404,0.9186413902053712,0.8575188425796945,0.8552103424039227
"Bart,DeBERTa,Pythia",0.9170616113744076,0.9161500855686666,0.9184486573173162,0.9170616113744076,0.8546299801935541,0.8523629917901695
DeBERTa-v3-base,0.9052132701421801,0.9041439414909381,0.913893753893425,0.8649703788944295,0.82636504002974,0.8248409479250016
BART-base,0.9004739336492891,0.9012021659745114,0.8783263941055242,0.8999345653105891,0.8245696886521976,0.823561032910586
T5-base,0.8996840442338072,0.8985763659739633,0.8994535427082456,0.8769829719382959,0.8171589791787418,0.8156503752760395
ALBERT,0.8902053712480252,0.8884323096232053,0.8972572573992004,0.8568480160252312,0.7992577028166675,0.7960388603378374
GPT-2,0.8815165876777251,0.8793242860566229,0.8744493675465215,0.8504712676529506,0.784237182833664,0.7809117486219015
Pythia,0.8507109004739336,0.8488239485819328,0.8409185766676891,0.796292723712679,0.7256179898496251,0.7244250649566035
