Model,Accuracy,F1,Precision,Recall,MCC,kappa
"T5,GPT2,Pythia",0.9167812929848692,0.9168805541235184,0.9176182700707258,0.9167812929848692,0.8452983770902398,0.8450997500416011
"DeBERTa,T5,GPT2",0.9160935350756534,0.9163045224392348,0.9166916394474406,0.9160935350756534,0.8447795741172949,0.8447059894666069
"DeBERTa,Albert,GPT2",0.9160935350756534,0.9163496347549464,0.917067456216721,0.9160935350756534,0.8455685561120675,0.8453548839865221
"DeBERTa,GPT2,Pythia",0.9154057771664376,0.9155118757138948,0.9156647783799232,0.9154057771664376,0.8428867235323623,0.8428714387505063
"T5,Albert,GPT2",0.9154057771664376,0.9155394738023532,0.91679544161058,0.9154057771664376,0.8440932327175189,0.843693217721446
"T5,Albert,Pythia",0.9133425034387896,0.9134909956720968,0.9141464931705192,0.9133425034387896,0.8390500567344765,0.8388914000488943
"DeBERTa,T5,Pythia",0.9099037138927096,0.9100540917973554,0.9102489205280772,0.9099037138927096,0.8330235345648093,0.8329907935116178
"DeBERTa,T5,Albert",0.9092159559834938,0.909527643429202,0.9100933694601544,0.9092159559834938,0.8327474440543068,0.8325760080393664
"DeBERTa,Albert,Pythia",0.905089408528198,0.9053568479535644,0.9058057538008186,0.905089408528198,0.8247771107549634,0.8246403042742243
"Bart,DeBERTa,GPT2",0.9009628610729024,0.8997861169854912,0.9024064622631626,0.9009628610729024,0.8274936036465349,0.8249680659680192
"Bart,T5,GPT2",0.9009628610729024,0.8997862340777365,0.902742140383754,0.9009628610729024,0.8275308274971428,0.8247682558174569
"Bart,T5,Albert",0.9002751031636864,0.8990662082670455,0.9024659630297454,0.9002751031636864,0.8263012958082284,0.8231683586856602
"Bart,Albert,GPT2",0.9002751031636864,0.8991333090619916,0.901603591881596,0.9002751031636864,0.8262803957276883,0.8238980157099375
"Bart,Albert,Pythia",0.8988995873452544,0.8976218732526262,0.901010769237336,0.8988995873452544,0.8237333162687698,0.8205095045028401
"Bart,GPT2,Pythia",0.8982118294360385,0.8969696299984891,0.9000200860387756,0.8982118294360385,0.8224520352061676,0.8194952389260574
"Bart,T5,Pythia",0.8982118294360385,0.8968962300121667,0.9005614482002899,0.8982118294360385,0.8225078628491356,0.8190453446170716
"Bart,DeBERTa,T5",0.8968363136176066,0.8956935847675708,0.8980906000249564,0.8968363136176066,0.8199726045117085,0.8175670928174467
"Bart,DeBERTa,Pythia",0.8947730398899587,0.8935489725572671,0.8963320833028889,0.8947730398899587,0.816165782099423,0.8133820775926286
"Bart,DeBERTa,Albert",0.8940852819807428,0.8930004712248223,0.8949435345895884,0.8940852819807428,0.8149999572638578,0.8129375478274237
T5-base,0.8651994497936726,0.8637127944916765,0.8572101236210946,0.8373411292109051,0.7559463637929748,0.754100920922182
DeBERTa-v3-base,0.8624484181568088,0.8612873505620356,0.8476765865819885,0.8368503270120865,0.7520753799558911,0.7497814459672478
"Albert,GPT2,Pythia",0.8562585969738652,0.854424845387155,0.8549450575184635,0.8562585969738652,0.7440540980514889,0.7424808398273974
BART-base,0.8555708390646493,0.8561680940093769,0.8307758950645158,0.8590870646577562,0.7463938111650573,0.7457694856773652
GPT-2,0.8473177441540578,0.8457128711793919,0.824423240547934,0.8355586971279741,0.7272891189497639,0.7250403979055273
Pythia,0.812242090784044,0.8083014244812426,0.8136228720441799,0.7651191271891565,0.6556464610850058,0.6507692118196264
ALBERT,0.8074277854195323,0.8076533194969648,0.7703522305185043,0.7987446333326162,0.6600359960709666,0.6594004537757758
