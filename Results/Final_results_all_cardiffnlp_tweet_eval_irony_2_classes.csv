Model,Accuracy,F1,Precision,Recall,MCC,kappa
"DeBERTa,Albert,Pythia",0.8391304347826087,0.8372781388696071,0.8449791599538503,0.8391304347826087,0.6802120018811942,0.672465553075206
"DeBERTa,GPT2,Pythia",0.8297101449275363,0.8281097448243059,0.833645659201603,0.8297101449275363,0.6594983426586306,0.6538052598542203
"DeBERTa,Albert,GPT2",0.827536231884058,0.8259948557340753,0.8310883375398828,0.827536231884058,0.6547795071951171,0.6495069791266488
"DeBERTa,T5,Albert",0.8253623188405798,0.8238801715100904,0.8285519012820417,0.8253623188405798,0.6500827982253046,0.6452116696749748
"DeBERTa,T5,Pythia",0.8253623188405798,0.8238801715100904,0.8285519012820417,0.8253623188405798,0.6500827982253046,0.6452116696749748
"DeBERTa,T5,GPT2",0.8173913043478261,0.8161270903010034,0.8194237361919792,0.8173913043478261,0.6330446698404653,0.629487572875115
"Albert,GPT2,Pythia",0.7971014492753623,0.7965507408139707,0.796169954238567,0.7971014492753623,0.5671626345587782,0.5670297162834477
"Bart,Albert,Pythia",0.7913043478260869,0.7880535117056857,0.8077317064413957,0.7913043478260869,0.5980829476250373,0.581255096815794
"Bart,T5,Pythia",0.7840579710144927,0.7810827953125543,0.7979801367900323,0.7840579710144927,0.5811624768809291,0.566797499636575
"T5,Albert,Pythia",0.7818840579710145,0.7786567877642018,0.7955638194342928,0.7818840579710145,0.5761004854457906,0.5616153258387122
"Bart,GPT2,Pythia",0.7811594202898551,0.7782947840375513,0.7941553385397981,0.7811594202898551,0.5744670566400292,0.5610159958035505
"Bart,Albert,GPT2",0.7782608695652173,0.7755067157916318,0.7903720966014537,0.7782608695652173,0.567811681113564,0.5552353688361423
"Bart,T5,Albert",0.777536231884058,0.7748096731451349,0.78943264495665,0.777536231884058,0.5661539772022718,0.5537903490811658
"T5,GPT2,Pythia",0.7760869565217391,0.7730904531372365,0.787954656824097,0.7760869565217391,0.5627561789986075,0.5500702718444144
"T5,Albert,GPT2",0.7717391304347826,0.7689154754893985,0.782355811762568,0.7717391304347826,0.5528528898897402,0.5414150620941096
"Bart,T5,GPT2",0.7702898550724637,0.7678380739859625,0.7801732470461148,0.7702898550724637,0.5497078332485003,0.539343164385812
"Bart,DeBERTa,Pythia",0.7673913043478261,0.7650485277488025,0.7765359168241965,0.7673913043478261,0.5431939349627516,0.5335658238884046
"Bart,DeBERTa,Albert",0.7666666666666667,0.7643510326676878,0.7756323100773839,0.7666666666666667,0.5415710428150808,0.5321216256341249
"Bart,DeBERTa,T5",0.7594202898550725,0.7573730895795516,0.7667178639711975,0.7594202898550725,0.525461058133758,0.5176826533770426
"Bart,DeBERTa,GPT2",0.7579710144927536,0.7559767339571402,0.7649607092864883,0.7579710144927536,0.5222642930649862,0.5147955155534502
DeBERTa-v3-base,0.7543478260869565,0.7541670614281967,0.7536898965307364,0.7529441884280594,0.5066335361594828,0.5065127406676033
BART-base,0.6956521739130435,0.695882583350614,0.6953167835737649,0.6959094270922228,0.3912257617868841,0.39085526191331976
ALBERT,0.6949275362318841,0.6906627874062162,0.6996860954555183,0.6887314862225257,0.3882630735637531,0.38144395753216387
T5-base,0.6891304347826087,0.6893470440187236,0.6886346826250672,0.6891613408937185,0.3777956564303974,0.37754702935944184
GPT-2,0.6811594202898551,0.6807041223323648,0.6800953642384105,0.6790692382090231,0.35916313663375166,0.35890532450666757
Pythia,0.6557971014492754,0.6464975664334339,0.6641507303117,0.6470102975479319,0.3106885753022364,0.29860941693095877
