Model,Accuracy,F1,Precision,Recall,MCC,kappa
"Bart,T5,GPT2",0.897708216880939,0.8982564091914595,0.8991287554072901,0.897708216880939,0.8096559200695588,0.8094135902412857
"Bart,DeBERTa,GPT2",0.8968697596422582,0.897396640789942,0.8983207765880744,0.8968697596422582,0.8081627878942752,0.8078785283320826
"Bart,DeBERTa,T5",0.8963107881498044,0.8968594813908394,0.8977968861661052,0.8963107881498044,0.807122260921228,0.8068414356767944
"Bart,DeBERTa,Albert",0.8960313024035774,0.8965352610811805,0.8974177015135205,0.8960313024035774,0.806487917104713,0.8062215386756632
"Bart,Albert,GPT2",0.8957518166573505,0.8962788317717898,0.8971086406656236,0.8957518166573505,0.8058698959369668,0.8056434713985446
"Bart,T5,Albert",0.8949133594186697,0.8954138200199769,0.8961749973478621,0.8949133594186697,0.8041445465095195,0.8039488053702307
"DeBERTa,T5,Albert",0.8940749021799889,0.8952131453385512,0.8980634766861614,0.8940749021799889,0.8010831550116119,0.8000420246441361
"DeBERTa,Albert,GPT2",0.8940749021799889,0.8951994743817682,0.8980226397125669,0.8940749021799889,0.8010221641171841,0.7999962242901444
"DeBERTa,T5,GPT2",0.8937954164337619,0.8948993757799282,0.8977174960743509,0.8937954164337619,0.800449313319963,0.7994300239228274
"Bart,GPT2,Pythia",0.8923979877026271,0.8927219528986324,0.8931578905593964,0.8923979877026271,0.798625547428168,0.7985482923701845
"Bart,Albert,Pythia",0.8910005589714924,0.8913315593764504,0.8917643404566646,0.8910005589714924,0.7959928620132597,0.7959186061238751
"Bart,T5,Pythia",0.8901621017328116,0.8904199953812825,0.8907484997159556,0.8901621017328116,0.7941182305834067,0.7940713694482244
"Bart,DeBERTa,Pythia",0.8898826159865847,0.8901511514449169,0.8904926143381853,0.8898826159865847,0.7936580307331744,0.7936039012471915
"DeBERTa,GPT2,Pythia",0.88848518725545,0.8893735808448182,0.8916452062598994,0.88848518725545,0.7891083844854125,0.7883926344103315
"DeBERTa,Albert,Pythia",0.8882057015092231,0.8891030345195827,0.8913521266236883,0.8882057015092231,0.7885597161649202,0.7878543659947981
"DeBERTa,T5,Pythia",0.8868082727780883,0.8876458592449197,0.8898160373666572,0.8868082727780883,0.7856700983526421,0.7850045778272924
BART-base,0.8761878144214645,0.8765309885465793,0.8398788170920142,0.846519811607542,0.7655951686030119,0.7655408920473145
DeBERTa-v3-base,0.8756288429290107,0.8752179256121231,0.8516973287083575,0.8381479335246516,0.7618131990033205,0.7615219364141375
"T5,Albert,GPT2",0.8750698714365568,0.8772864260859532,0.882379363323511,0.8750698714365568,0.7636500462965516,0.7614172065499037
"Albert,GPT2,Pythia",0.8728339854667412,0.8751163980480047,0.8806160186098272,0.8728339854667412,0.7576231246431296,0.7554420487232134
"T5,GPT2,Pythia",0.8708775852431526,0.8728151059597249,0.8768796923590079,0.8708775852431526,0.7537888290050265,0.752148226826364
"T5,Albert,Pythia",0.869200670765791,0.8711920064863676,0.875266763603601,0.869200670765791,0.7504510105785498,0.7488395952044902
ALBERT,0.8580212409167133,0.856200923997472,0.8305763161918739,0.8010375437442162,0.7244646637553191,0.7234979241320937
T5-base,0.8563443264393515,0.8548597188134368,0.8253615670843791,0.8033836161402504,0.7218092159550465,0.7210973323134205
GPT-2,0.8524315259921744,0.8521006149810464,0.8103679610485687,0.8049047260337657,0.7182858362191059,0.7181959375240532
Pythia,0.8479597540525433,0.8409407753819444,0.8513057959704304,0.751766177515606,0.6983112585991151,0.6866855794032315
